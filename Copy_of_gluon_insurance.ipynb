{
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.12",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 84896,
          "databundleVersionId": 10305135,
          "sourceType": "competition"
        }
      ],
      "dockerImageVersionId": 30822,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/fvangool/datasharing/blob/master/Copy_of_gluon_insurance.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install autogluon.tabular[all]"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:45:05.254951Z",
          "iopub.execute_input": "2024-12-28T10:45:05.255483Z",
          "iopub.status.idle": "2024-12-28T10:45:11.601619Z",
          "shell.execute_reply.started": "2024-12-28T10:45:05.255441Z",
          "shell.execute_reply": "2024-12-28T10:45:11.597677Z"
        },
        "id": "GHmJJiEMv5hY",
        "outputId": "9900e401-8291-4e01-e223-dd99359326ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: autogluon.tabular[all] in /usr/local/lib/python3.10/dist-packages (1.2)\n",
            "Requirement already satisfied: numpy<2.1.4,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.16,>=1.5.4 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.13.1)\n",
            "Requirement already satisfied: pandas<2.3.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn<1.5.3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.5.2)\n",
            "Requirement already satisfied: networkx<4,>=3.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (3.4.2)\n",
            "Requirement already satisfied: autogluon.core==1.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.2)\n",
            "Requirement already satisfied: autogluon.features==1.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.2)\n",
            "Requirement already satisfied: catboost<1.3,>=1.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (1.2.7)\n",
            "Requirement already satisfied: spacy<3.8 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (3.7.5)\n",
            "Requirement already satisfied: lightgbm<4.6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (4.5.0)\n",
            "Requirement already satisfied: einops<0.9,>=0.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (0.8.0)\n",
            "Requirement already satisfied: xgboost<2.2,>=1.6 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (2.1.3)\n",
            "Requirement already satisfied: fastai<2.8,>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (2.7.18)\n",
            "Requirement already satisfied: huggingface-hub[torch] in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (0.27.0)\n",
            "Requirement already satisfied: torch<2.6,>=2.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.tabular[all]) (2.5.1+cu121)\n",
            "Requirement already satisfied: tqdm<5,>=4.38 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (4.67.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (2.32.3)\n",
            "Requirement already satisfied: matplotlib<3.11,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (3.8.0)\n",
            "Requirement already satisfied: boto3<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (1.35.90)\n",
            "Requirement already satisfied: autogluon.common==1.2 in /usr/local/lib/python3.10/dist-packages (from autogluon.core==1.2->autogluon.tabular[all]) (1.2)\n",
            "Requirement already satisfied: ray<2.40,>=2.10.0 in /usr/local/lib/python3.10/dist-packages (from ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.39.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (17.0.0)\n",
            "Requirement already satisfied: hyperopt<0.2.8,>=0.2.7 in /usr/local/lib/python3.10/dist-packages (from autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.2.7)\n",
            "Requirement already satisfied: psutil<7.0.0,>=5.7.3 in /usr/local/lib/python3.10/dist-packages (from autogluon.common==1.2->autogluon.core==1.2->autogluon.tabular[all]) (5.9.5)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (0.20.3)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (5.24.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost<1.3,>=1.2->autogluon.tabular[all]) (1.17.0)\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.1.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (24.2)\n",
            "Requirement already satisfied: fastdownload<2,>=0.0.5 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.0.7)\n",
            "Requirement already satisfied: fastcore<1.8,>=1.5.29 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.7.27)\n",
            "Requirement already satisfied: torchvision>=0.11 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (0.20.1+cu121)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (6.0.2)\n",
            "Requirement already satisfied: fastprogress>=0.2.4 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from fastai<2.8,>=2.3.1->autogluon.tabular[all]) (11.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<2.3.0,>=2.0.0->autogluon.tabular[all]) (2024.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.tabular[all]) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<1.5.3,>=1.4.0->autogluon.tabular[all]) (3.5.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.0.11)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.0.10)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.5.0)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (0.15.1)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (2.10.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (75.1.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8->autogluon.tabular[all]) (3.5.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (4.12.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch<2.6,>=2.2->autogluon.tabular[all]) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch<2.6,>=2.2->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: nvidia-nccl-cu12 in /usr/local/lib/python3.10/dist-packages (from xgboost<2.2,>=1.6->autogluon.tabular[all]) (2.23.4)\n",
            "Requirement already satisfied: safetensors[torch] in /usr/local/lib/python3.10/dist-packages (from huggingface-hub[torch]; extra == \"all\"->autogluon.tabular[all]) (0.4.5)\n",
            "Requirement already satisfied: botocore<1.36.0,>=1.35.90 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all]) (1.35.90)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all]) (1.0.1)\n",
            "Requirement already satisfied: s3transfer<0.11.0,>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from boto3<2,>=1.10->autogluon.core==1.2->autogluon.tabular[all]) (0.10.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.0)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (3.1.0)\n",
            "Requirement already satisfied: py4j in /usr/local/lib/python3.10/dist-packages (from hyperopt<0.2.8,>=0.2.7->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.10.9.7)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]) (1.3.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (1.4.7)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<3.11,>=3.7.0->autogluon.core==1.2->autogluon.tabular[all]) (3.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8->autogluon.tabular[all]) (2.27.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (8.1.7)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.23.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.1.0)\n",
            "Requirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.25.5)\n",
            "Requirement already satisfied: aiosignal in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.3.2)\n",
            "Requirement already satisfied: frozenlist in /usr/local/lib/python3.10/dist-packages (from ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.5.0)\n",
            "Requirement already satisfied: aiohttp>=3.7 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (3.11.10)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.7.0)\n",
            "Requirement already satisfied: colorful in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.5.6)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.0)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.11.4)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.21.1)\n",
            "Requirement already satisfied: smart-open in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (7.1.0)\n",
            "Requirement already satisfied: virtualenv!=20.21.1,>=20.0.24 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (20.28.0)\n",
            "Requirement already satisfied: grpcio>=1.42.0 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.68.1)\n",
            "Requirement already satisfied: memray in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.15.0)\n",
            "Requirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.10/dist-packages (from ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.6.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->autogluon.core==1.2->autogluon.tabular[all]) (2024.12.14)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8->autogluon.tabular[all]) (0.1.5)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (13.9.4)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8->autogluon.tabular[all]) (0.20.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8->autogluon.tabular[all]) (3.0.2)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost<1.3,>=1.2->autogluon.tabular[all]) (9.0.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.4.4)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (24.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.7->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.18.3)\n",
            "Requirement already satisfied: marisa-trie>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8->autogluon.tabular[all]) (1.2.1)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (2.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.17.0)\n",
            "Requirement already satisfied: distlib<1,>=0.3.7 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.3.9)\n",
            "Requirement already satisfied: platformdirs<5,>=3.9.1 in /usr/local/lib/python3.10/dist-packages (from virtualenv!=20.21.1,>=20.0.24->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.3.6)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2024.10.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.35.1)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema->ray<2.40,>=2.10.0->ray[default]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.22.3)\n",
            "Requirement already satisfied: textual>=0.41.0 in /usr/local/lib/python3.10/dist-packages (from memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.0)\n",
            "Requirement already satisfied: opencensus-context>=0.1.3 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.1.3)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.19.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.66.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.25.0)\n",
            "Requirement already satisfied: google-auth<3.0.dev0,>=2.14.1 in /usr/local/lib/python3.10/dist-packages (from google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.27.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8->autogluon.tabular[all]) (0.1.2)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (5.5.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (4.9)\n",
            "Requirement already satisfied: mdit-py-plugins in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.4.2)\n",
            "Requirement already satisfied: linkify-it-py<3,>=1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (2.0.3)\n",
            "Requirement already satisfied: uc-micro-py in /usr/local/lib/python3.10/dist-packages (from linkify-it-py<3,>=1->markdown-it-py[linkify,plugins]>=2.1.0->textual>=0.41.0->memray->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (1.0.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.dev0,>=2.14.1->google-api-core<3.0.0,>=1.0.0->opencensus->ray[default,tune]<2.40,>=2.10.0; extra == \"all\"->autogluon.core[all]==1.2; extra == \"all\"->autogluon.tabular[all]) (0.6.1)\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dask[dataframe]"
      ],
      "metadata": {
        "id": "S0YPN0_57hjQ",
        "outputId": "29eb4764-93a8-454e-b3d8-53ba9bbb3433",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: dask[dataframe] in /usr/local/lib/python3.10/dist-packages (2024.10.0)\n",
            "Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (3.1.0)\n",
            "Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2024.10.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (24.2)\n",
            "Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.4.2)\n",
            "Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (6.0.2)\n",
            "Requirement already satisfied: toolz>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (0.12.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.13.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (8.5.0)\n",
            "Requirement already satisfied: pandas>=2.0 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (2.2.2)\n",
            "Requirement already satisfied: dask-expr<1.2,>=1.1 in /usr/local/lib/python3.10/dist-packages (from dask[dataframe]) (1.1.16)\n",
            "Requirement already satisfied: pyarrow>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from dask-expr<1.2,>=1.1->dask[dataframe]) (17.0.0)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata>=4.13.0->dask[dataframe]) (3.21.0)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0->dask[dataframe]) (2024.2)\n",
            "Requirement already satisfied: locket in /usr/local/lib/python3.10/dist-packages (from partd>=1.4.0->dask[dataframe]) (1.0.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0->dask[dataframe]) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Read the CSV file\n",
        "data = pd.read_csv('/content/drive/My Drive/train.csv')"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:45:11.604073Z",
          "iopub.execute_input": "2024-12-28T10:45:11.604949Z",
          "iopub.status.idle": "2024-12-28T10:45:21.40029Z",
          "shell.execute_reply.started": "2024-12-28T10:45:11.60485Z",
          "shell.execute_reply": "2024-12-28T10:45:21.396283Z"
        },
        "id": "t1IeZZcLv5hZ",
        "outputId": "7b3a025d-367a-45e6-81ef-d9402c799b2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "#drop 'id' column\n",
        "data.drop(\"id\", axis=1, inplace=True)\n",
        "# log the target\n",
        "data['Premium Amount'] = np.log1p(data['Premium Amount'])"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:45:21.404323Z",
          "iopub.execute_input": "2024-12-28T10:45:21.405454Z",
          "iopub.status.idle": "2024-12-28T10:45:21.864169Z",
          "shell.execute_reply.started": "2024-12-28T10:45:21.4054Z",
          "shell.execute_reply": "2024-12-28T10:45:21.861187Z"
        },
        "id": "WadO47Ewv5hZ"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "#  Split the data into training and test sets\n",
        "train_data = data.sample(frac=0.8, random_state=42)\n",
        "test_data = data.drop(train_data.index)"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:45:21.876564Z",
          "iopub.execute_input": "2024-12-28T10:45:21.877961Z",
          "iopub.status.idle": "2024-12-28T10:45:23.451484Z",
          "shell.execute_reply.started": "2024-12-28T10:45:21.877844Z",
          "shell.execute_reply": "2024-12-28T10:45:23.450466Z"
        },
        "id": "JXve0x8Qv5ha"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import PolynomialFeatures,  StandardScaler\n",
        "\n",
        "###### predicting nans\n",
        "\n",
        "class ImputePreviousClaims(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.imputer = None\n",
        "        self.predictors = ['Annual Income', 'Health Score', 'Credit Score']\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Create a complete copy at the start\n",
        "        X_copy = X.copy()\n",
        "\n",
        "        # Create mask for known values\n",
        "        mask = X_copy['Previous Claims'].notna()\n",
        "\n",
        "        # Initialize and fit the imputer\n",
        "        self.imputer = SimpleImputer(strategy='mean')\n",
        "        X_predictors = self.imputer.fit_transform(X_copy.loc[mask, self.predictors])\n",
        "\n",
        "        # Train the model\n",
        "        self.model = RandomForestRegressor(random_state=42)\n",
        "        self.model.fit(X_predictors, X_copy.loc[mask, 'Previous Claims'])\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Create a complete copy\n",
        "        X_copy = X.copy()\n",
        "\n",
        "        # Impute predictors for all rows\n",
        "        X_copy.loc[:, self.predictors] = self.imputer.transform(X_copy[self.predictors])\n",
        "\n",
        "        # Predict missing values\n",
        "        mask = X_copy['Previous Claims'].isna()\n",
        "        if mask.any():\n",
        "            missing_predictions = self.model.predict(X_copy.loc[mask, self.predictors])\n",
        "            X_copy.loc[mask, 'Previous Claims'] = missing_predictions\n",
        "\n",
        "        return X_copy\n",
        "\n",
        "###### start feature creation\n",
        "\n",
        "class InsuranceFeatureTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self):\n",
        "        self.predictors = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X_copy = X.copy()\n",
        "\n",
        "        # 1. Risk Score Components\n",
        "        # Normalize credit score (300-850 scale)\n",
        "        X_copy['normalized_credit_score'] = (X_copy['Credit Score'] - 300) / (850 - 300)\n",
        "\n",
        "        # Health risk indicator\n",
        "        X_copy['health_risk_score'] = (60 - X_copy['Health Score']) / 60  # Invert so higher is riskier\n",
        "        X_copy['health_risk_score'] = np.where(X_copy['Smoking Status'] == 'Yes',\n",
        "                                             X_copy['health_risk_score'] * 1.5,  # Penalty for smokers\n",
        "                                             X_copy['health_risk_score'])\n",
        "\n",
        "        # 2. Financial Stability Indicators\n",
        "        # Income brackets (using percentiles for normalization)\n",
        "        X_copy['income_bracket'] = pd.qcut(X_copy['Annual Income'], q=5, labels=['Very Low', 'Low', 'Medium', 'High', 'Very High'])\n",
        "\n",
        "        # Disposable income proxy (considering dependents)\n",
        "        X_copy['income_per_dependent'] = X_copy['Annual Income'] / (X_copy['Number of Dependents'] + 1)\n",
        "\n",
        "        # 3. Claims Risk Features\n",
        "        # Claims frequency (claims per year of insurance)\n",
        "        X_copy['claims_per_year'] = X_copy['Previous Claims'] / X_copy['Insurance Duration']\n",
        "\n",
        "        # Binary high-risk indicator\n",
        "        X_copy['high_risk_customer'] = np.where(\n",
        "            (X_copy['Previous Claims'] > 2) & (X_copy['Insurance Duration'] < 3), 1, 0\n",
        "        )\n",
        "\n",
        "        # Claims history score\n",
        "        X_copy['claims_history_score'] = 1 - (X_copy['Previous Claims'] / X_copy['Previous Claims'].max())\n",
        "\n",
        "        # 4. Vehicle Risk Features\n",
        "        # Vehicle age risk brackets\n",
        "        X_copy['vehicle_age_risk'] = pd.cut(\n",
        "            X_copy['Vehicle Age'],\n",
        "            bins=[0, 3, 7, 12, float('inf')],\n",
        "            labels=['New', 'Low_Risk', 'Medium_Risk', 'High_Risk']\n",
        "        )\n",
        "\n",
        "        # 5. Lifestyle Risk Score\n",
        "        X_copy['lifestyle_risk'] = 0\n",
        "\n",
        "        # Exercise frequency impact\n",
        "        exercise_risk = {\n",
        "            'Daily': 0,\n",
        "            'Weekly': 0.25,\n",
        "            'Monthly': 0.75,\n",
        "            'Rarely': 1\n",
        "        }\n",
        "        X_copy['lifestyle_risk'] += X_copy['Exercise Frequency'].map(exercise_risk)\n",
        "\n",
        "        # Property type risk\n",
        "        property_risk = {\n",
        "            'House': 1,\n",
        "            'Condo': 0.75,\n",
        "            'Apartment': 0.5\n",
        "        }\n",
        "        X_copy['lifestyle_risk'] += X_copy['Property Type'].map(property_risk)\n",
        "\n",
        "        # Location risk\n",
        "        location_risk = {\n",
        "            'Urban': 1,\n",
        "            'Suburban': 0.5,\n",
        "            'Rural': 0.75  # Higher due to emergency response times\n",
        "        }\n",
        "        X_copy['lifestyle_risk'] += X_copy['Location'].map(location_risk)\n",
        "        X_copy['lifestyle_risk'] /= 3  # Normalize to 0-1\n",
        "\n",
        "        # 6. Customer Profile Features\n",
        "        # Policy type risk level\n",
        "        policy_risk = {\n",
        "            'Premium': 3,\n",
        "            'Comprehensive': 2,\n",
        "            'Basic': 1\n",
        "        }\n",
        "        X_copy['policy_risk_level'] = X_copy['Policy Type'].map(policy_risk)\n",
        "\n",
        "        # Customer stability score\n",
        "        X_copy['customer_stability'] = (\n",
        "            X_copy['Insurance Duration'] *\n",
        "            X_copy['normalized_credit_score'] *\n",
        "            (1 - X_copy['claims_per_year'].clip(0, 1))\n",
        "        )\n",
        "\n",
        "        # 7. Demographic Risk Score\n",
        "        # Age risk brackets\n",
        "        def assign_risk(age):\n",
        "            if 18 <= age <= 25:\n",
        "                return 'High_Risk'\n",
        "            elif 25 < age <= 35:\n",
        "                return 'Medium_Risk'\n",
        "            elif 35 < age <= 50:\n",
        "                return 'Low_Risk'\n",
        "            elif 50 < age <= 65:\n",
        "                return 'Medium_Risk'\n",
        "\n",
        "        X_copy['age_risk'] = X_copy['Age'].apply(assign_risk)\n",
        "        \"\"\"X_copy['age_risk'] = pd.cut(\n",
        "            X_copy['Age'],\n",
        "            bins=[18, 25, 35, 50, 65],\n",
        "            labels=['High_Risk', 'Medium_Risk', 'Low_Risk', 'Medium_Risk']\n",
        "        )\"\"\"\n",
        "\n",
        "        # Combined demographic risk\n",
        "        marital_risk = {\n",
        "            'Single': 0.8,\n",
        "            'Married': 0.4,\n",
        "            'Divorced': 0.6\n",
        "        }\n",
        "        X_copy['demographic_risk'] = (\n",
        "            X_copy['Marital Status'].map(marital_risk) *\n",
        "            (1 + (X_copy['Number of Dependents'] / 4))  # Normalize by max dependents\n",
        "        )\n",
        "\n",
        "        # 8. Education Impact\n",
        "        education_level = {\n",
        "            'PhD': 0.2,\n",
        "            \"Master's\": 0.3,\n",
        "            \"Bachelor's\": 0.4,\n",
        "            'High School': 0.5\n",
        "        }\n",
        "        X_copy['education_risk_factor'] = X_copy['Education Level'].map(education_level)\n",
        "\n",
        "        return X_copy\n",
        "\n",
        "#end futurecreation\n",
        "\n",
        "# Custom Transformer for dropping columns\n",
        "class DropColumns(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        return X.drop(columns=self.columns, axis=1)\n",
        "\n",
        "# Custom Transformer for logging specific columns\n",
        "class LogTransform(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for column in self.columns:\n",
        "            X[column] = np.log1p(X[column])\n",
        "        return X\n",
        "\n",
        "# Custom Transformer for calculating Policy Duration since Start\n",
        "class PolicyDurationTransform(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column):\n",
        "        self.column = column\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        year = pd.to_datetime(X[self.column]).dt.year\n",
        "        X['Policyduration_ss'] = 2024 - year\n",
        "        return X.drop(columns=[self.column])\n",
        "\n",
        "# Custom Transformer for handling NaNs and creating binary indicators\n",
        "class NanHandlingTransform(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, columns):\n",
        "        self.columns = columns\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = X.copy()\n",
        "        for column in self.columns:\n",
        "            indicator_column = f\"{column} Present\"\n",
        "            X[indicator_column] = X[column].isna().astype(int)\n",
        "            X[column] = X[column].fillna(-1)\n",
        "        return X\n",
        "#custom polynomialdegrees pipeline for selected features\n",
        "\n",
        "class CustomFeatureTransformer(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, selected_features):\n",
        "        self.selected_features = selected_features\n",
        "        self.imputer = SimpleImputer(strategy='mean')\n",
        "        self.poly = PolynomialFeatures(degree=2, include_bias=False)\n",
        "        self.scaler = StandardScaler()\n",
        "        self.poly_feature_names = None\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        # Get selected features data\n",
        "        X_selected = X[self.selected_features]\n",
        "\n",
        "        # Fit imputer\n",
        "        self.imputer.fit(X_selected)\n",
        "\n",
        "        # Fit polynomial features\n",
        "        X_imputed = self.imputer.transform(X_selected)\n",
        "        X_poly = self.poly.fit_transform(X_imputed)\n",
        "        self.poly_feature_names = self.poly.get_feature_names_out(self.selected_features)\n",
        "\n",
        "        # Fit scaler\n",
        "        self.scaler.fit(X_poly)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        # Copy input data\n",
        "        X_copy = X.copy()\n",
        "\n",
        "        # Transform selected features\n",
        "        X_selected = X_copy[self.selected_features]\n",
        "\n",
        "        # Apply imputation\n",
        "        X_imputed = self.imputer.transform(X_selected)\n",
        "\n",
        "        # Generate polynomial features\n",
        "        X_poly = self.poly.transform(X_imputed)\n",
        "\n",
        "        # Scale features\n",
        "        X_scaled = self.scaler.transform(X_poly)\n",
        "\n",
        "        # Create DataFrame with transformed features\n",
        "        X_transformed = pd.DataFrame(\n",
        "            X_scaled,\n",
        "            columns=self.poly_feature_names,\n",
        "            index=X.index\n",
        "        )\n",
        "\n",
        "        # Replace original features with transformed ones\n",
        "        for col in self.selected_features:\n",
        "            if col in X_copy.columns:\n",
        "                X_copy.drop(col, axis=1, inplace=True)\n",
        "\n",
        "        # Combine transformed features with remaining features\n",
        "        result = pd.concat([X_transformed, X_copy], axis=1)\n",
        "\n",
        "        return result\n",
        "\n",
        "\n",
        "\n",
        "# Define the pipeline\n",
        "pipeline = Pipeline([\n",
        "    #('drop_columns', DropColumns(columns=['id'])),\n",
        "    #('impute_claims', ImputePreviousClaims()),\n",
        "    (\"feature_creation\", InsuranceFeatureTransformer()),\n",
        "    ('log_transform', LogTransform(columns=['Annual Income'])),\n",
        "    #('log_transform', LogTransform(columns=['Premium Amount', 'Annual Income'])),\n",
        "    ('policy_duration', PolicyDurationTransform(column='Policy Start Date')),\n",
        "    #('nan_handling', NanHandlingTransform(columns=['Previous Claims', 'Occupation']))\n",
        "    ('nan_handling', NanHandlingTransform(columns=['Occupation'])),\n",
        "    ('feature_transformer', CustomFeatureTransformer(selected_features=['Annual Income', 'Health Score','Credit Score', 'normalized_credit_score'])),\n",
        "    #('polynomial_features', PolynomialFeatures(degree=2, include_bias=False)),#, ['Annual Income', 'Health Score','Credit Score', 'normalized_credit_score'])\n",
        "    #('nan_handling', SimpleImputer(strategy='mean'))\n",
        "])\n",
        "\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:45:23.453247Z",
          "iopub.execute_input": "2024-12-28T10:45:23.45369Z",
          "iopub.status.idle": "2024-12-28T10:45:24.524718Z",
          "shell.execute_reply.started": "2024-12-28T10:45:23.453643Z",
          "shell.execute_reply": "2024-12-28T10:45:24.523505Z"
        },
        "id": "4JEA5l32v5ha"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "current_timestamp = datetime.now()\n",
        "print(f\"Current Timestamp: {current_timestamp}\")\n",
        "transformed_train = pipeline.fit_transform(train_data)\n",
        "from datetime import datetime\n",
        "current_timestamp = datetime.now()\n",
        "print(f\"Current Timestamp: {current_timestamp}\")\n",
        "transformed_test = pipeline.transform(test_data)\n",
        "from datetime import datetime\n",
        "current_timestamp = datetime.now()\n",
        "print(f\"Current Timestamp: {current_timestamp}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:45:24.525957Z",
          "iopub.execute_input": "2024-12-28T10:45:24.526533Z",
          "iopub.status.idle": "2024-12-28T10:56:01.129409Z",
          "shell.execute_reply.started": "2024-12-28T10:45:24.526481Z",
          "shell.execute_reply": "2024-12-28T10:56:01.127741Z"
        },
        "id": "77ICT2ILv5hb",
        "outputId": "d1878017-1042-4004-c0db-612d14867913",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Timestamp: 2024-12-30 11:26:13.615734\n",
            "Current Timestamp: 2024-12-30 11:26:26.309927\n",
            "Current Timestamp: 2024-12-30 11:26:28.599706\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "from autogluon.core.metrics import make_scorer\n",
        "from sklearn.metrics import root_mean_squared_log_error\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "## create custom scorer metric\n",
        "\n",
        "def root_mean_squared_log_error_cust(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the root mean squared log error.\n",
        "\n",
        "    Parameters:\n",
        "        y_true (array-like): True target values.\n",
        "        y_pred (array-like): Predicted target values.\n",
        "\n",
        "    Returns:\n",
        "        float: RMSLE value.\n",
        "    \"\"\"\n",
        "    #y_true = np.maximum(0, y_true)  # Ensure no negative values\n",
        "    #y_pred = np.maximum(0, y_pred)  # Ensure no negative values\n",
        "    #return np.sqrt(np.mean((np.log1p(y_pred) - np.log1p(y_true))**2))\n",
        "\n",
        "    return root_mean_squared_log_error(y_true, y_pred)\n",
        "\n",
        "#  AutoGluon Scorer\n",
        "ag_rmsle_scorer = make_scorer(name='root_mean_squared_log_error',\n",
        "                              score_func=root_mean_squared_log_error,\n",
        "                              optimum=0,  # The best value of RMSLE is 0\n",
        "                              greater_is_better=False)  # Lower is better for RMSLE"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:56:01.131214Z",
          "iopub.execute_input": "2024-12-28T10:56:01.131709Z",
          "iopub.status.idle": "2024-12-28T10:56:01.532058Z",
          "shell.execute_reply.started": "2024-12-28T10:56:01.131658Z",
          "shell.execute_reply": "2024-12-28T10:56:01.530743Z"
        },
        "id": "gExj3aV1v5hc"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "current_timestamp = datetime.now()\n",
        "print(f\"Current Timestamp: {current_timestamp}\")\n",
        "\n",
        "\n",
        "from autogluon.tabular import TabularPredictor\n",
        "#set path for model save\n",
        "save_path = '/kaggle/working/'\n",
        "# Define target column and split into train/test\n",
        "target = 'Premium Amount'\n",
        "#set runtime limit\n",
        "time_limit=1800#10800\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Initialize and train AutoGluon\n",
        "# Initialize and train AutoGluon\n",
        "predictor = TabularPredictor(label=target, path=save_path, eval_metric=ag_rmsle_scorer, problem_type='regression').fit(transformed_train,time_limit=time_limit,\n",
        "    presets='medium_quality' ) #time * 16 for best quality\n",
        "\n",
        "leaderboard = predictor.leaderboard(data=None, extra_info=True)\n",
        "\n",
        "# Print the leaderboard\n",
        "print(leaderboard)\n",
        "\n",
        "# Evaluate on test data\n",
        "performance = predictor.evaluate(transformed_test)\n",
        "print(\"test performance\",performance)\n",
        "\n",
        "from datetime import datetime\n",
        "current_timestamp = datetime.now()\n",
        "print(f\"Current Timestamp: {current_timestamp}\")"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-28T10:56:01.533298Z",
          "iopub.execute_input": "2024-12-28T10:56:01.534074Z",
          "iopub.status.idle": "2024-12-28T14:09:32.861993Z",
          "shell.execute_reply.started": "2024-12-28T10:56:01.534023Z",
          "shell.execute_reply": "2024-12-28T14:09:32.860108Z"
        },
        "id": "kpHJZ-6sv5hd",
        "outputId": "a1def594-e5b6-4b90-bfaa-da6dc9d17c6f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Warning: path already exists! This predictor may overwrite an existing predictor! path=\"/kaggle/working/\"\n",
            "Verbosity: 2 (Standard Logging)\n",
            "=================== System Info ===================\n",
            "AutoGluon Version:  1.2\n",
            "Python Version:     3.10.12\n",
            "Operating System:   Linux\n",
            "Platform Machine:   x86_64\n",
            "Platform Version:   #1 SMP PREEMPT_DYNAMIC Thu Jun 27 21:05:47 UTC 2024\n",
            "CPU Count:          2\n",
            "Memory Avail:       7.35 GB / 12.67 GB (58.0%)\n",
            "Disk Space Avail:   73.14 GB / 107.72 GB (67.9%)\n",
            "===================================================\n",
            "Presets specified: ['medium_quality']\n",
            "Beginning AutoGluon training ... Time limit = 1800s\n",
            "AutoGluon will save models to \"/kaggle/working\"\n",
            "Train Data Rows:    960000\n",
            "Train Data Columns: 44\n",
            "Label Column:       Premium Amount\n",
            "Problem Type:       regression\n",
            "Preprocessing data ...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Current Timestamp: 2024-12-30 11:26:28.678278\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using Feature Generators to preprocess the data ...\n",
            "Fitting AutoMLPipelineFeatureGenerator...\n",
            "\tAvailable Memory:                    8376.16 MB\n",
            "\tTrain Data (Original)  Memory Usage: 855.82 MB (10.2% of available memory)\n",
            "\tWarning: Data size prior to feature transformation consumes 10.2% of available memory. Consider increasing memory or subsampling the data to avoid instability.\n",
            "\tInferring data type of each feature based on column values. Set feature_metadata_in to manually specify special dtypes of the features.\n",
            "\tStage 1 Generators:\n",
            "\t\tFitting AsTypeFeatureGenerator...\n",
            "\t\t\tNote: Converting 4 features to boolean dtype as they only contain 2 unique values.\n",
            "\tStage 2 Generators:\n",
            "\t\tFitting FillNaFeatureGenerator...\n",
            "\tStage 3 Generators:\n",
            "\t\tFitting IdentityFeatureGenerator...\n",
            "\t\tFitting CategoryFeatureGenerator...\n",
            "\t\t\tFitting CategoryMemoryMinimizeFeatureGenerator...\n",
            "\t\tFitting DatetimeFeatureGenerator...\n",
            "\tStage 4 Generators:\n",
            "\t\tFitting DropUniqueFeatureGenerator...\n",
            "\tStage 5 Generators:\n",
            "\t\tFitting DropDuplicatesFeatureGenerator...\n",
            "\tUnused Original Features (Count: 1): ['Occupation']\n",
            "\t\tThese features were not used to generate any of the output features. Add a feature generator compatible with these features to utilize them.\n",
            "\t\tFeatures can also be unused if they carry very little information, such as being categorical but having almost entirely unique values or being duplicates of other features.\n",
            "\t\tThese features do not need to be present at inference time.\n",
            "\t\t('object', ['datetime_as_object']) : 1 | ['Occupation']\n",
            "\tTypes of features in original data (raw dtype, special dtypes):\n",
            "\t\t('category', []) :  2 | ['income_bracket', 'vehicle_age_risk']\n",
            "\t\t('float', [])    : 27 | ['Annual Income', 'Health Score', 'Credit Score', 'normalized_credit_score', 'Annual Income^2', ...]\n",
            "\t\t('int', [])      :  4 | ['high_risk_customer', 'policy_risk_level', 'Policyduration_ss', 'Occupation Present']\n",
            "\t\t('object', [])   : 10 | ['Gender', 'Marital Status', 'Education Level', 'Location', 'Policy Type', ...]\n",
            "\tTypes of features in processed data (raw dtype, special dtypes):\n",
            "\t\t('category', [])  : 10 | ['Marital Status', 'Education Level', 'Location', 'Policy Type', 'Customer Feedback', ...]\n",
            "\t\t('float', [])     : 27 | ['Annual Income', 'Health Score', 'Credit Score', 'normalized_credit_score', 'Annual Income^2', ...]\n",
            "\t\t('int', [])       :  2 | ['policy_risk_level', 'Policyduration_ss']\n",
            "\t\t('int', ['bool']) :  4 | ['Gender', 'Smoking Status', 'high_risk_customer', 'Occupation Present']\n",
            "\t22.8s = Fit runtime\n",
            "\t43 features in original data used to generate 43 features in processed data.\n",
            "\tTrain Data (Processed) Memory Usage: 221.56 MB (2.7% of available memory)\n",
            "Data preprocessing and feature engineering runtime = 24.44s ...\n",
            "AutoGluon will gauge predictive performance using evaluation metric: 'root_mean_squared_log_error'\n",
            "\tThis metric's sign has been flipped to adhere to being higher_is_better. The metric score can be multiplied by -1 to get the metric value.\n",
            "\tTo change this, specify the eval_metric parameter of Predictor()\n",
            "Automatically generating train/validation split with holdout_frac=0.01, Train Rows: 950400, Val Rows: 9600\n",
            "User-specified model hyperparameters to be fit:\n",
            "{\n",
            "\t'NN_TORCH': [{}],\n",
            "\t'GBM': [{'extra_trees': True, 'ag_args': {'name_suffix': 'XT'}}, {}, {'learning_rate': 0.03, 'num_leaves': 128, 'feature_fraction': 0.9, 'min_data_in_leaf': 3, 'ag_args': {'name_suffix': 'Large', 'priority': 0, 'hyperparameter_tune_kwargs': None}}],\n",
            "\t'CAT': [{}],\n",
            "\t'XGB': [{}],\n",
            "\t'FASTAI': [{}],\n",
            "\t'RF': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'XT': [{'criterion': 'gini', 'ag_args': {'name_suffix': 'Gini', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'entropy', 'ag_args': {'name_suffix': 'Entr', 'problem_types': ['binary', 'multiclass']}}, {'criterion': 'squared_error', 'ag_args': {'name_suffix': 'MSE', 'problem_types': ['regression', 'quantile']}}],\n",
            "\t'KNN': [{'weights': 'uniform', 'ag_args': {'name_suffix': 'Unif'}}, {'weights': 'distance', 'ag_args': {'name_suffix': 'Dist'}}],\n",
            "}\n",
            "Fitting 11 L1 models, fit_strategy=\"sequential\" ...\n",
            "Fitting model: KNeighborsUnif ... Training model for up to 1775.56s of the 1775.55s of remaining time.\n",
            "\t-0.1735\t = Validation score   (-root_mean_squared_log_error)\n",
            "\t4.19s\t = Training   runtime\n",
            "\t75.4s\t = Validation runtime\n",
            "Fitting model: KNeighborsDist ... Training model for up to 1695.35s of the 1695.34s of remaining time.\n",
            "\t-0.1738\t = Validation score   (-root_mean_squared_log_error)\n",
            "\t2.61s\t = Training   runtime\n",
            "\t75.92s\t = Validation runtime\n",
            "Fitting model: LightGBMXT ... Training model for up to 1616.27s of the 1616.26s of remaining time.\n",
            "\t-0.1561\t = Validation score   (-root_mean_squared_log_error)\n",
            "\t92.2s\t = Training   runtime\n",
            "\t0.36s\t = Validation runtime\n",
            "Fitting model: LightGBM ... Training model for up to 1523.60s of the 1523.59s of remaining time.\n",
            "\t-0.1554\t = Validation score   (-root_mean_squared_log_error)\n",
            "\t42.37s\t = Training   runtime\n",
            "\t0.1s\t = Validation runtime\n",
            "Fitting model: RandomForestMSE ... Training model for up to 1481.11s of the 1481.10s of remaining time.\n",
            "\tWarning: Model is expected to require 12993.4s to train, which exceeds the maximum time limit of 1480.1s, skipping model...\n",
            "\tTime limit exceeded... Skipping RandomForestMSE.\n",
            "Fitting model: CatBoost ... Training model for up to 1306.21s of the 1306.20s of remaining time.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from datetime import datetime\n",
        "current_timestamp = datetime.now()\n",
        "print(f\"Current Timestamp: {current_timestamp}\")\n",
        "\n",
        "\n",
        "y_pred = predictor.predict(transformed_test)\n",
        "perf = predictor.evaluate_predictions(y_true=transformed_test[target], y_pred=y_pred, auxiliary_metrics=True)\n",
        "\n",
        "from datetime import datetime\n",
        "current_timestamp = datetime.now()\n",
        "print(f\"Current Timestamp: {current_timestamp}\")\n",
        "\n",
        "y_pred_train = predictor.predict(transformed_train)\n",
        "perf_train = predictor.evaluate_predictions(y_true=transformed_train[target], y_pred=y_pred_train, auxiliary_metrics=True)\n",
        "\n",
        "#set to rmsle\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "\n",
        "print(\"ypred\", y_pred.shape)\n",
        "print(\"test_data[target]\", test_data[target].shape)\n",
        "print(\"ypred train\", y_pred_train.shape)\n",
        "print(\"train_data[target]\", train_data[target].shape)\n",
        "\n",
        "test_msle_pred = mean_squared_log_error(test_data[target], y_pred)\n",
        "train_msle_pred = mean_squared_log_error(train_data[target], y_pred_train)\n",
        "test_rmsle_pred = np.sqrt(test_msle_pred)\n",
        "train_rmsle_pred = np.sqrt(train_msle_pred)\n",
        "print(\"rmsle prediction on test\" , test_rmsle_pred)\n",
        "print(\"rmsle prediction on train\", train_rmsle_pred)\n"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "execution_failed": "2024-12-28T15:01:33.947Z"
        },
        "id": "UnUUDEIdv5hd"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "testos = pd.read_csv(\"/kaggle/input/playground-series-s4e12/test.csv\")\n",
        "id = testos['id']\n",
        "testos.drop(\"id\", axis=1, inplace=True)\n",
        "testy = pipeline.transform(testos)\n",
        "\n",
        "from datetime import datetime\n",
        "current_timestamp = datetime.now()\n",
        "print(f\"Current Timestamp: {current_timestamp}\")\n",
        "\n",
        "y_testset_pred = predictor.predict(testy)\n",
        "# Convert H2OFrame to numpy array (get only the predictions column)\n",
        "#y_testset_pred = y_testset_pred['predict'].as_data_frame().values\n",
        "y_testset_pred = np.expm1(y_testset_pred.values)\n",
        "premium = pd.DataFrame(y_testset_pred, columns=['Premium Amount'])\n",
        "premium_round = round(premium['Premium Amount'] , 3)\n",
        "submission = pd.concat([id, premium_round], axis=1)\n",
        "print(submission.columns)\n",
        "print(submission.head())\n",
        "#submission.to_csv('submission.csv', index=False, sep=',')\n",
        "#submission.to_csv('/kaggle/working/submission.csv', index=False, sep=',')\n",
        "print(\"submission file updated\")\n",
        "from datetime import datetime\n",
        "current_timestamp = datetime.now()\n",
        "print(f\"Current Timestamp: {current_timestamp}\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "PkQbP7qrv5he"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "from autogluon.tabular import TabularPredictor\n",
        "\n",
        "# Load the predictor from the path where it was saved\n",
        "loaded_predictor = TabularPredictor.load(\"/kaggle/working/\")"
      ],
      "metadata": {
        "trusted": true,
        "id": "KlbqTdodv5he"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# Get feature importance\n",
        "feature_importances = predictor.feature_importance(data=transformed_test)\n",
        "print(feature_importances)\n",
        "\n",
        "# Visualize feature importance (if available)\n",
        "predictor.plot_feature_importance(data=transformed_test)"
      ],
      "metadata": {
        "trusted": true,
        "id": "5Jw4qMChv5he"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "leaderboard = predictor.leaderboard()\n",
        "print(leaderboard)"
      ],
      "metadata": {
        "trusted": true,
        "id": "cGHpy9lnv5hf"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "predictor.model_names()\n",
        "print(transformed_train.columns)\n",
        "print(test_data.columns)"
      ],
      "metadata": {
        "trusted": true,
        "id": "84vKRFrTv5hf"
      },
      "outputs": [],
      "execution_count": null
    }
  ]
}